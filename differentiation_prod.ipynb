{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token_index = {'\\t': 0,\n",
    " '\\n': 1,\n",
    " '0': 2,\n",
    " '1': 3,\n",
    " '2': 4,\n",
    " '3': 5,\n",
    " '4': 6,\n",
    " '5': 7,\n",
    " '6': 8,\n",
    " '7': 9,\n",
    " '8': 10,\n",
    " '9': 11,\n",
    " 'A': 12,\n",
    " 'B': 13,\n",
    " 'C': 14,\n",
    " 'D': 15,\n",
    " 'a': 16,\n",
    " 'c': 17,\n",
    " 'd': 18,\n",
    " 'e': 19,\n",
    " 'f': 20,\n",
    " 'g': 21,\n",
    " 'h': 22,\n",
    " 'j': 23,\n",
    " 'k': 24,\n",
    " 'l': 25,\n",
    " 'm': 26,\n",
    " 'n': 27,\n",
    " 'o': 28,\n",
    " 'p': 29,\n",
    " 'q': 30,\n",
    " 'r': 31,\n",
    " 's': 32,\n",
    " 't': 33,\n",
    " 'u': 34,\n",
    " 'v': 35,\n",
    " 'y': 36,\n",
    " 'z': 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = {'0': 0,\n",
    " '1': 1,\n",
    " '2': 2,\n",
    " '3': 3,\n",
    " '4': 4,\n",
    " '5': 5,\n",
    " '6': 6,\n",
    " '7': 7,\n",
    " '8': 8,\n",
    " '9': 9,\n",
    " 'A': 10,\n",
    " 'B': 11,\n",
    " 'C': 12,\n",
    " 'D': 13,\n",
    " 'a': 14,\n",
    " 'b': 15,\n",
    " 'c': 16,\n",
    " 'd': 17,\n",
    " 'f': 18,\n",
    " 'g': 19,\n",
    " 'h': 20,\n",
    " 'i': 21,\n",
    " 'j': 22,\n",
    " 'k': 23,\n",
    " 'l': 24,\n",
    " 'm': 25,\n",
    " 'n': 26,\n",
    " 'o': 27,\n",
    " 'p': 28,\n",
    " 'q': 29,\n",
    " 'r': 30,\n",
    " 's': 31,\n",
    " 't': 32,\n",
    " 'u': 33,\n",
    " 'v': 34,\n",
    " 'w': 35,\n",
    " 'y': 36,\n",
    " 'z': 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_char_index = {0: '\\t',\n",
    " 1: '\\n',\n",
    " 2: '0',\n",
    " 3: '1',\n",
    " 4: '2',\n",
    " 5: '3',\n",
    " 6: '4',\n",
    " 7: '5',\n",
    " 8: '6',\n",
    " 9: '7',\n",
    " 10: '8',\n",
    " 11: '9',\n",
    " 12: 'A',\n",
    " 13: 'B',\n",
    " 14: 'C',\n",
    " 15: 'D',\n",
    " 16: 'a',\n",
    " 17: 'c',\n",
    " 18: 'd',\n",
    " 19: 'e',\n",
    " 20: 'f',\n",
    " 21: 'g',\n",
    " 22: 'h',\n",
    " 23: 'j',\n",
    " 24: 'k',\n",
    " 25: 'l',\n",
    " 26: 'm',\n",
    " 27: 'n',\n",
    " 28: 'o',\n",
    " 29: 'p',\n",
    " 30: 'q',\n",
    " 31: 'r',\n",
    " 32: 's',\n",
    " 33: 't',\n",
    " 34: 'u',\n",
    " 35: 'v',\n",
    " 36: 'y',\n",
    " 37: 'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_decoder_seq_length = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model('diff_enc.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "decoder_model = load_model('diff_dec.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    # Loop untill we recieve a stop sign\n",
    "    while not stop_condition:\n",
    "        # Get output and internal states of the decoder \n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Get the predicted token (the token with the highest score)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        # Get the character belonging to the token\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        # Append char to output\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lettoword(let):\n",
    "    my_dict = {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9', 'E': 'a', 'I': 'b', '(+)': 'c', '(-)': 'd', \"Y'\": 'e', 'abs': 'f', 'acos': 'g', 'acosh': 'h', 'acoth': 'i', '+': 'j', 'asin': 'k', 'asinh': 'l', 'atan': 'm', 'atanh': 'n', 'cos': 'o', 'cosh': 'p', '/': 'q', 'exp': 'r', 'ln': 's', '*': 't', 'pi': 'u', 'pow': 'v', 'sign': 'w', 'sin': 'x', 'sinh': 'y', 'sqrt': 'z', '-': 'A', 'tan': 'B', 'tanh': 'C', 'x': 'D'}\n",
    "    rev = {v:k for k, v in my_dict.items()}\n",
    "    let = list(let)\n",
    "    ret = []\n",
    "    for key in let:\n",
    "        ret.append(rev[key])\n",
    "    return \" \".join(ret)\n",
    "        \n",
    "def wordtolet(word):\n",
    "    my_dict = {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9', 'E': 'a', 'I': 'b', '(+)': 'c', '(-)': 'd', \"Y'\": 'e', 'abs': 'f', 'acos': 'g', 'acosh': 'h', 'acoth': 'i', '+': 'j', 'asin': 'k', 'asinh': 'l', 'atan': 'm', 'atanh': 'n', 'cos': 'o', 'cosh': 'p', '/': 'q', 'exp': 'r', 'ln': 's', '*': 't', 'pi': 'u', 'pow': 'v', 'sign': 'w', 'sin': 'x', 'sinh': 'y', 'sqrt': 'z', '-': 'A', 'tan': 'B', 'tanh': 'C', 'x': 'D'}\n",
    "    word = word.split()\n",
    "    ret = []\n",
    "    for key in word:\n",
    "        ret.append(my_dict[key])\n",
    "    return \"\".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(text):\n",
    "    my_text = wordtolet(text)\n",
    "    placeholder = np.zeros((1,len(my_text)+10,num_encoder_tokens))\n",
    "    for i, char in enumerate(my_text):\n",
    "        #print(i,char, input_token_index[char])\n",
    "        placeholder[0,i,input_token_index[char]] = 1\n",
    "    sol = decode_sequence(placeholder)[:-1]\n",
    "    sol = lettoword(sol)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples():\n",
    "    train_lines = open('minialpha2.train').read().split('\\n')\n",
    "    for train_line in train_lines[5:6]:\n",
    "        train_target_eq, train_input_eq = train_line.split('\\t')\n",
    "        train_input_eq = lettoword(train_input_eq)\n",
    "        train_target_eq = lettoword(train_target_eq)\n",
    "        #if(solve(train_input_eq) == train_target_eq):\n",
    "        print(\"\\nInput: \" + train_input_eq + \"\\nPrediction: \" + solve(train_input_eq) + \"\\nTarget: \" + train_target_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: + pow x (+) 2 * / (+) 1 (+) 3 pow x (+) 3\n",
      "Prediction: - Y' * x + (+) 1 + x * (+) 2 pow x (+) 2\n",
      "Target: - Y' + pow x (+) 2 * (+) 2 x\n"
     ]
    }
   ],
   "source": [
    "print_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: * / (+) 4 (+) 3 pow x (+) 3\n",
      "Prediction: - Y' * x + (+) 1 + x * (+) 2 pow x (+) 2\n",
      "Target: - Y' * (+) 4 pow x (+) 2\n"
     ]
    }
   ],
   "source": [
    "print_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
